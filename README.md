# Explore Ollama

## Overview

[Ollama](https://ollama.com) allows you to run Large Language Models (LLMs) locally on your machine, providing privacy and control over your AI interactions. This project serves as an example of how to integrate and work with [Ollama](https://ollama.com) in a locally hosted environment on macOS.

This project was developed and tested on the following:

- 2021 14" MacBook Pro
    - Apple M1 Max
    - 64GB RAM
    - 2TB SSD
    - macOS - `Sequoia 15.2`
    - Node.js - `v22.12.0`
    - npm - `v10.9.0`

## Installation

### Install Ollama

To install Ollama, follow these steps:

- Open a web browser and navigate to https://ollama.com/download
- Download the appropriate version for your operating system (macOS, Linux, Windows)
- On macOS, drag the downloaded file to the Applications folder
- Launch Ollama from the Applications folder and follow the instructions to complete the installation

Please see [Ollama](https://ollama.com/) for additional information.
