# Explore Ollama

## Overview

[Ollama](https://ollama.com) allows you to run Large Language Models (LLMs) locally on your machine, providing privacy and control over your AI interactions. This project serves as an example of how to integrate and work with [Ollama](https://ollama.com) in a locally hosted environment on macOS.

## System Requirements

This project was developed and tested on the following:

- 2021 14" MacBook Pro
    - Apple M1 Max
    - 64GB RAM
    - 2TB SSD
    - macOS - `Sequoia 15.2`
    - Node.js - `v22.12.0`
    - npm - `v10.9.0`

## Installation

1. First, install Ollama by following the instructions at [ollama.com](https://ollama.com)

2. Clone this repository:   
 ```bash
    # Clone the repository
    git clone https://github.com/TheRobBrennan/explore-ollama.git

    # Navigate to the project directory
    cd explore-ollama
 ```
